{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train First Pytorch Model?\n",
    "- The model will take and card image and try to predict which number that image is \n",
    "- Image classifier to detect playing cards\n",
    "\n",
    "- Most important parts of Pytorch:\n",
    "    -  Pytorch Dataset\n",
    "    -  Pytorch Model\n",
    "    -  Pytorch Traning Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_ctx' from 'torch.library' (/opt/anaconda3/envs/pytorch_apple/lib/python3.8/site-packages/torch/library.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransofrms\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageFolder\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtimm\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_apple/lib/python3.8/site-packages/torchvision/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodulefinder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_apple/lib/python3.8/site-packages/torchvision/_meta_registrations.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_custom_ops\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibrary\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Ensure that torch.ops.torchvision is visible\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_apple/lib/python3.8/site-packages/torch/_custom_ops.py:10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_custom_op\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     _custom_op_with_schema,\n\u001b[1;32m      5\u001b[0m     _find_custom_op,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     validate_namespace,\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibrary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_ctx\n\u001b[1;32m     12\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom_op\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimpl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimpl_backward\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m ]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom_op\u001b[39m(qualname, func_or_schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_ctx' from 'torch.library' (/opt/anaconda3/envs/pytorch_apple/lib/python3.8/site-packages/torch/library.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transofrms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import timm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement get_ctx (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for get_ctx\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install get_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model:\n",
      "TinyModel(\n",
      "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "\n",
      "\n",
      "Just one layer:\n",
      "Linear(in_features=200, out_features=10, bias=True)\n",
      "\n",
      "\n",
      "Model params:\n",
      "Parameter containing:\n",
      "tensor([[-0.0674,  0.0195,  0.0785,  ...,  0.0003, -0.0153, -0.0601],\n",
      "        [ 0.0871,  0.0833,  0.0092,  ...,  0.0417, -0.0787, -0.0836],\n",
      "        [-0.0990,  0.0520,  0.0826,  ...,  0.0841, -0.0821,  0.0769],\n",
      "        ...,\n",
      "        [-0.0914, -0.0131, -0.0094,  ...,  0.0136,  0.0947, -0.0475],\n",
      "        [-0.0464, -0.0894,  0.0932,  ...,  0.0394,  0.0011, -0.0148],\n",
      "        [ 0.0529, -0.0013, -0.0045,  ..., -0.0366, -0.0090,  0.0173]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0126,  0.0829,  0.0362,  0.0489, -0.0329,  0.0635,  0.0268,  0.0645,\n",
      "         0.0237,  0.0847,  0.0743, -0.0909,  0.0610, -0.0438, -0.0276,  0.0795,\n",
      "        -0.0900,  0.0932,  0.0650, -0.0897,  0.0097,  0.0136,  0.0160,  0.0770,\n",
      "         0.0788, -0.0601, -0.0225, -0.0128, -0.0625, -0.0199, -0.0986, -0.0866,\n",
      "        -0.0605, -0.0290,  0.0144,  0.0667, -0.0515, -0.0076, -0.0190,  0.0289,\n",
      "        -0.0401,  0.0274, -0.0840,  0.0089,  0.0337,  0.0774, -0.0717,  0.0517,\n",
      "        -0.0920, -0.0230,  0.0987, -0.0010, -0.0649, -0.0106, -0.0165, -0.0438,\n",
      "         0.0268, -0.0516, -0.0702,  0.0639, -0.0270, -0.0395, -0.0711,  0.0737,\n",
      "        -0.0199, -0.0526, -0.0160, -0.0357, -0.0571, -0.0274,  0.0733,  0.0503,\n",
      "         0.0372,  0.0768,  0.0188,  0.0849, -0.0855,  0.0185,  0.0115,  0.0946,\n",
      "         0.0402, -0.0576, -0.0672, -0.0960, -0.0034,  0.0919,  0.0844, -0.0660,\n",
      "        -0.0707, -0.0067, -0.0899,  0.0815,  0.0903, -0.0835,  0.0075, -0.0221,\n",
      "        -0.0719, -0.0776,  0.0717,  0.0626,  0.0186, -0.0824,  0.0551,  0.0457,\n",
      "         0.0212, -0.0942,  0.0954,  0.0018, -0.0829,  0.0297,  0.0723,  0.0101,\n",
      "        -0.0717,  0.0896, -0.0484,  0.0826,  0.0312, -0.0827, -0.0781, -0.0565,\n",
      "         0.0268,  0.0546,  0.0607, -0.0133, -0.0175,  0.0210,  0.0476, -0.0215,\n",
      "         0.0271,  0.0452,  0.0767, -0.0497,  0.0672,  0.0378,  0.0954,  0.0534,\n",
      "         0.0960,  0.0529, -0.0341,  0.0172,  0.0379,  0.0146, -0.0372, -0.0332,\n",
      "         0.0775,  0.0878, -0.0647, -0.0278,  0.0240,  0.0837,  0.0902, -0.0421,\n",
      "         0.0845,  0.0423, -0.0707,  0.0924,  0.0955,  0.0675,  0.0591,  0.0844,\n",
      "        -0.0549,  0.0004,  0.0130, -0.0776,  0.0575, -0.0488,  0.0996, -0.0745,\n",
      "        -0.0403, -0.0411,  0.0482, -0.0528,  0.0346, -0.0364,  0.0537, -0.0849,\n",
      "        -0.0504,  0.0029,  0.0444, -0.0908,  0.0660,  0.0991,  0.0857, -0.0642,\n",
      "         0.0203,  0.0944,  0.0611, -0.0792,  0.0337,  0.0197, -0.0341,  0.0978,\n",
      "        -0.0640, -0.0590,  0.0447,  0.0756, -0.0852,  0.0546, -0.0762, -0.0090],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0452, -0.0097, -0.0229,  ..., -0.0004, -0.0046,  0.0374],\n",
      "        [-0.0321, -0.0276, -0.0696,  ..., -0.0109, -0.0522,  0.0544],\n",
      "        [-0.0426, -0.0125, -0.0026,  ..., -0.0248,  0.0563, -0.0609],\n",
      "        ...,\n",
      "        [ 0.0009,  0.0573, -0.0584,  ..., -0.0173,  0.0615, -0.0444],\n",
      "        [ 0.0479,  0.0659,  0.0278,  ...,  0.0047, -0.0258, -0.0175],\n",
      "        [ 0.0026, -0.0577,  0.0694,  ..., -0.0699, -0.0228, -0.0627]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0404, -0.0250, -0.0123, -0.0102,  0.0252,  0.0211,  0.0252, -0.0332,\n",
      "        -0.0400,  0.0533], requires_grad=True)\n",
      "\n",
      "\n",
      "Layer params:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0452, -0.0097, -0.0229,  ..., -0.0004, -0.0046,  0.0374],\n",
      "        [-0.0321, -0.0276, -0.0696,  ..., -0.0109, -0.0522,  0.0544],\n",
      "        [-0.0426, -0.0125, -0.0026,  ..., -0.0248,  0.0563, -0.0609],\n",
      "        ...,\n",
      "        [ 0.0009,  0.0573, -0.0584,  ..., -0.0173,  0.0615, -0.0444],\n",
      "        [ 0.0479,  0.0659,  0.0278,  ...,  0.0047, -0.0258, -0.0175],\n",
      "        [ 0.0026, -0.0577,  0.0694,  ..., -0.0699, -0.0228, -0.0627]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0404, -0.0250, -0.0123, -0.0102,  0.0252,  0.0211,  0.0252, -0.0332,\n",
      "        -0.0400,  0.0533], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(100, 200)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(200, 10)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "tinymodel = TinyModel()\n",
    "\n",
    "print('The model:')\n",
    "print(tinymodel)\n",
    "\n",
    "print('\\n\\nJust one layer:')\n",
    "print(tinymodel.linear2)\n",
    "\n",
    "print('\\n\\nModel params:')\n",
    "for param in tinymodel.parameters():\n",
    "    print(param)\n",
    "\n",
    "print('\\n\\nLayer params:')\n",
    "for param in tinymodel.linear2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_apple",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
